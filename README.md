This hash map project was created for The Odin Project's JavaScript course.

Once I had come to understand how a hash map stores and retrieves data, I began to wonder: why not have our buckets be objects instead of linked lists/arrays? The Odin Project's descriptions of hash maps propose using linked lists to resolve collisions. That is to say, if a bucket contains keys A, B, and C and we want to retrieve the value for key C, we'd hash C, go to that bucket, then iterate over the linked list until we find (or don't find) the relevant key. With an object as our bucket, we need only check bucket[key] instead of iterating. This makes the get, has, and remove methods faster if there are collisions. So, that's how I chose to implement the buckets. It also makes for cleaner looking code as we avoid iteration.

While working on this project, I also wondered if I could find a way to avoid collisions entirely. I added a new method that would take a hash code, check if the bucket at that index were populated and move to the next bucket until we found an empty one, then return a new hash code for that index. After testing, this method did allow for avoiding collisions entirely, and it also worked with the has, get, and remove methods. However, it introduced some issues if we tried to iterate over an index that had previously held an item that had been removed (as the remove method sets such items to be null). I reflected on whether or not I wanted to fix this or forgo the collision checker, but realized that in adding my collision checker, I was making the set method (or anything that had to retrieve data) less efficient. For each key set, you'd have an average number of populated buckets to iterate over before finding a good hash code, which would increase as the total amount of keys approached the rehash threshold. Without collision checking, it's unlikely that the index you land on will have anything in its bucket so no iteration is required. If you do get a collision, you may only have to iterate over 1 or 2 keys in the bucket to find what you're looking for as opposed to iterating over an average number of indices determined by the capacity of the hash map (this could be anywhere from 1-5 in my testing). I'd like to be able to quantitatively compare the approaches but for now I'm not sure how I'd go about that. So, I decided to forgo the collision checker and stick more closely to The Odin Project's specifications for the project.

Creating a hash set was relatively simple and required only minor code adjustments. I removed a few irrelevant methods like get and values. I also made it so every key has a value of "true" so they can be detected for retrieval.
